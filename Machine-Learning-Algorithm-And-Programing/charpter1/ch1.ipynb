{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#机器学习的基础\" data-toc-modified-id=\"机器学习的基础-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>机器学习的基础</a></div><div class=\"lev2 toc-item\"><a href=\"#编程语言与开发环境\" data-toc-modified-id=\"编程语言与开发环境-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>编程语言与开发环境</a></div><div class=\"lev2 toc-item\"><a href=\"#对象、矩阵与矢量化编程\" data-toc-modified-id=\"对象、矩阵与矢量化编程-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>对象、矩阵与矢量化编程</a></div><div class=\"lev3 toc-item\"><a href=\"#对象和维度\" data-toc-modified-id=\"对象和维度-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>对象和维度</a></div><div class=\"lev3 toc-item\"><a href=\"#初识矩阵\" data-toc-modified-id=\"初识矩阵-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>初识矩阵</a></div><div class=\"lev3 toc-item\"><a href=\"#矢量化编程和GPU运算\" data-toc-modified-id=\"矢量化编程和GPU运算-123\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>矢量化编程和GPU运算</a></div><div class=\"lev3 toc-item\"><a href=\"#理解数学公式与-Numpy-矩阵运算\" data-toc-modified-id=\"理解数学公式与-Numpy-矩阵运算-124\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>理解数学公式与 Numpy 矩阵运算</a></div><div class=\"lev4 toc-item\"><a href=\"#矩阵的初始化\" data-toc-modified-id=\"矩阵的初始化-1241\"><span class=\"toc-item-num\">1.2.4.1&nbsp;&nbsp;</span>矩阵的初始化</a></div><div class=\"lev4 toc-item\"><a href=\"#矩阵的元素运算：-是指矩阵在元素级别的加、减、乘、除运算\" data-toc-modified-id=\"矩阵的元素运算：-是指矩阵在元素级别的加、减、乘、除运算-1242\"><span class=\"toc-item-num\">1.2.4.2&nbsp;&nbsp;</span>矩阵的元素运算： 是指矩阵在元素级别的加、减、乘、除运算</a></div><div class=\"lev4 toc-item\"><a href=\"#矩阵的乘法：矩阵乘矩阵\" data-toc-modified-id=\"矩阵的乘法：矩阵乘矩阵-1243\"><span class=\"toc-item-num\">1.2.4.3&nbsp;&nbsp;</span>矩阵的乘法：矩阵乘矩阵</a></div><div class=\"lev4 toc-item\"><a href=\"#矩阵的转置\" data-toc-modified-id=\"矩阵的转置-1244\"><span class=\"toc-item-num\">1.2.4.4&nbsp;&nbsp;</span>矩阵的转置</a></div><div class=\"lev4 toc-item\"><a href=\"#矩阵的其他操作：行列数、切片、复制、比较\" data-toc-modified-id=\"矩阵的其他操作：行列数、切片、复制、比较-1245\"><span class=\"toc-item-num\">1.2.4.5&nbsp;&nbsp;</span>矩阵的其他操作：行列数、切片、复制、比较</a></div><div class=\"lev3 toc-item\"><a href=\"#Linalg-线性代数库\" data-toc-modified-id=\"Linalg-线性代数库-125\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>Linalg 线性代数库</a></div><div class=\"lev4 toc-item\"><a href=\"#矩阵的行列式\" data-toc-modified-id=\"矩阵的行列式-1251\"><span class=\"toc-item-num\">1.2.5.1&nbsp;&nbsp;</span>矩阵的行列式</a></div><div class=\"lev4 toc-item\"><a href=\"#矩阵的逆\" data-toc-modified-id=\"矩阵的逆-1252\"><span class=\"toc-item-num\">1.2.5.2&nbsp;&nbsp;</span>矩阵的逆</a></div><div class=\"lev4 toc-item\"><a href=\"#矩阵的对称\" data-toc-modified-id=\"矩阵的对称-1253\"><span class=\"toc-item-num\">1.2.5.3&nbsp;&nbsp;</span>矩阵的对称</a></div><div class=\"lev4 toc-item\"><a href=\"#矩阵的秩\" data-toc-modified-id=\"矩阵的秩-1254\"><span class=\"toc-item-num\">1.2.5.4&nbsp;&nbsp;</span>矩阵的秩</a></div><div class=\"lev4 toc-item\"><a href=\"#可逆矩阵求解\" data-toc-modified-id=\"可逆矩阵求解-1255\"><span class=\"toc-item-num\">1.2.5.5&nbsp;&nbsp;</span>可逆矩阵求解</a></div><div class=\"lev2 toc-item\"><a href=\"#机器学习的数学基础\" data-toc-modified-id=\"机器学习的数学基础-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>机器学习的数学基础</a></div><div class=\"lev3 toc-item\"><a href=\"#相似度的度量\" data-toc-modified-id=\"相似度的度量-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>相似度的度量</a></div><div class=\"lev3 toc-item\"><a href=\"#各类距离的意义与python实现\" data-toc-modified-id=\"各类距离的意义与python实现-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>各类距离的意义与python实现</a></div><div class=\"lev4 toc-item\"><a href=\"#闵可夫斯基距离(Minkowski-Distance)\" data-toc-modified-id=\"闵可夫斯基距离(Minkowski-Distance)-1321\"><span class=\"toc-item-num\">1.3.2.1&nbsp;&nbsp;</span>闵可夫斯基距离(Minkowski Distance)</a></div><div class=\"lev4 toc-item\"><a href=\"#欧氏距离(Euclidean-Distance)\" data-toc-modified-id=\"欧氏距离(Euclidean-Distance)-1322\"><span class=\"toc-item-num\">1.3.2.2&nbsp;&nbsp;</span>欧氏距离(Euclidean Distance)</a></div><div class=\"lev4 toc-item\"><a href=\"#曼哈顿距离(Manhattan-Distance)\" data-toc-modified-id=\"曼哈顿距离(Manhattan-Distance)-1323\"><span class=\"toc-item-num\">1.3.2.3&nbsp;&nbsp;</span>曼哈顿距离(Manhattan Distance)</a></div><div class=\"lev4 toc-item\"><a href=\"#切比雪夫距离(Chebyshev-Distance)\" data-toc-modified-id=\"切比雪夫距离(Chebyshev-Distance)-1324\"><span class=\"toc-item-num\">1.3.2.4&nbsp;&nbsp;</span>切比雪夫距离(Chebyshev Distance)</a></div><div class=\"lev4 toc-item\"><a href=\"#夹角余弦(Cosine)\" data-toc-modified-id=\"夹角余弦(Cosine)-1325\"><span class=\"toc-item-num\">1.3.2.5&nbsp;&nbsp;</span>夹角余弦(Cosine)</a></div><div class=\"lev4 toc-item\"><a href=\"#汉明距离(Hamming-distance)\" data-toc-modified-id=\"汉明距离(Hamming-distance)-1326\"><span class=\"toc-item-num\">1.3.2.6&nbsp;&nbsp;</span>汉明距离(Hamming distance)</a></div><div class=\"lev4 toc-item\"><a href=\"#杰卡德相似系数(Jaccard-similarity-coefficient)\" data-toc-modified-id=\"杰卡德相似系数(Jaccard-similarity-coefficient)-1327\"><span class=\"toc-item-num\">1.3.2.7&nbsp;&nbsp;</span>杰卡德相似系数(Jaccard similarity coefficient)</a></div><div class=\"lev3 toc-item\"><a href=\"#理解随机性\" data-toc-modified-id=\"理解随机性-133\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>理解随机性</a></div><div class=\"lev3 toc-item\"><a href=\"#回顾概率论\" data-toc-modified-id=\"回顾概率论-134\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>回顾概率论</a></div><div class=\"lev3 toc-item\"><a href=\"#多元统计基础\" data-toc-modified-id=\"多元统计基础-135\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;</span>多元统计基础</a></div><div class=\"lev3 toc-item\"><a href=\"#特征间的相关性\" data-toc-modified-id=\"特征间的相关性-136\"><span class=\"toc-item-num\">1.3.6&nbsp;&nbsp;</span>特征间的相关性</a></div><div class=\"lev4 toc-item\"><a href=\"#相关系数-(-Correlation-coefficient-)与相关距离(Correlation-distance)\" data-toc-modified-id=\"相关系数-(-Correlation-coefficient-)与相关距离(Correlation-distance)-1361\"><span class=\"toc-item-num\">1.3.6.1&nbsp;&nbsp;</span>相关系数 ( Correlation coefficient )与相关距离(Correlation distance)</a></div><div class=\"lev4 toc-item\"><a href=\"#马氏距离(Mahalanobis-Distance)\" data-toc-modified-id=\"马氏距离(Mahalanobis-Distance)-1362\"><span class=\"toc-item-num\">1.3.6.2&nbsp;&nbsp;</span>马氏距离(Mahalanobis Distance)</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习的基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程语言与开发环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAFkCAYAAABW9YMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a00ad29d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Filename:mytest1.py\n",
    "\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataSet = [[-0.017612,14.053064],[-1.395634\t,4.662541],[-0.752157\t,6.538620],[-1.322371\t,7.152853],\n",
    "[0.423363\t,11.054677],[0.406704\t,7.067335],[0.667394\t,12.741452],[-2.460150\t,6.866805],\n",
    "[0.569411\t,9.548755],[-0.026632\t,10.427743],[0.850433\t,6.920334],[1.347183\t,13.175500],\n",
    "[1.176813\t,3.167020],[-1.781871\t,9.097953]]\n",
    "\n",
    "dataMat = mat(dataSet).T #将数据集转换为NumPy矩阵，并转置\n",
    "plt.scatter(dataMat[0],dataMat[1],c='red',marker='o') #绘制数据集散点图\n",
    "\n",
    "#绘制直线图形\n",
    "X = np.linspace(-2,2,100) #产生直线数据集\n",
    "#建立线性方程\n",
    "Y = 2.8*X+9\n",
    "\n",
    "plt.plot(X,Y) #绘制直线图\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 对象、矩阵与矢量化编程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对象和维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初识矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 矢量化编程和GPU运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传统的计算机语言是针对标量的，程序设计复杂度比较高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 30, 40, 50]\n"
     ]
    }
   ],
   "source": [
    "mylist = [1,2,3,4,5]\n",
    "length = len(mylist)\n",
    "a = 10\n",
    "for indx in xrange(length):\n",
    "    mylist[indx] = a*mylist[indx]\n",
    "print mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于矩阵的算法都是针对向量的。处理基于矩阵的基本运算，就是矢量化编程。\n",
    "最早实现矢量化编程的语言是MATLAB，极大降低数学领域程序设计复杂度，大量的人工智能算法最早都是用MATLAB编写的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "扩展包NumPy提供了专门的矩阵数据结构和线性代数库。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 20 30 40 50]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mylist = [1,2,3,4,5]\n",
    "a = 10\n",
    "mymatrix = np.mat(mylist)\n",
    "print a*mymatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矢量化编程的一个重要特点就是可以直接将数学公式转化为相应的程序代码。\n",
    "\n",
    "英伟达(nVidia)公司在 1999 年发布 GeForce256 图形处理芯片时首先提出了 GPU 运算的概念。十几年的发展使单个 GPU 芯片在浮点运算、大规模并行计算方面，可以 提供数十倍乃至上百倍于 CPU 的性能。GPU 的流处理器也由几十个增加到最新的三千 多个，浮点运算 TFlops 值也达到 5 以上。本书的第十章的深度学习部分专门讲解了 GPU 运算的 Python 框架 Theano。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 理解数学公式与 Numpy 矩阵运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵的初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # 导入 numpy 包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 创建一个 3*5 的全零矩阵和全 1 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n",
      "[[ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "myZeros = np.zeros([3,5])\n",
    "print myZeros\n",
    "myOnes = np.ones([3,5]) # np.ones((3,5))\n",
    "print myOnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 生成随机矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.112767    0.65709419  0.02060741  0.0466832 ]\n",
      " [ 0.93072145  0.45864437  0.83753068  0.56442171]\n",
      " [ 0.39765701  0.68503257  0.17430428  0.38624345]]\n"
     ]
    }
   ],
   "source": [
    "myRand = np.random.rand(3,4) #3*4的0~1之间的随机数\n",
    "print myRand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 单位矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "myEye = np.eye(3) #3*3的单位矩阵\n",
    "print myEye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵的元素运算： 是指矩阵在元素级别的加、减、乘、除运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import * #导入 numpy 包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 元素相加和相减：\n",
    "条件：矩阵的行数和列数必须相同\n",
    "\n",
    "$$(A\\pm B)_{i,j}=A_{i,j}\\pm B_{i,j} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  1.  1.]\n",
      " [ 1.  2.  1.]\n",
      " [ 1.  1.  2.]]\n",
      "[[ 0.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "myOnes = ones([3,3])\n",
    "myEye = eye(3)\n",
    "print myOnes + myEye\n",
    "print myOnes - myEye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 矩阵数乘：一个数乘以一个矩阵\n",
    "\n",
    "$$(cA)_{i,j} = c\\cdot A_{i,j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 20 30]\n",
      " [40 50 60]\n",
      " [70 80 90]]\n"
     ]
    }
   ],
   "source": [
    "mymatrix = mat([[1,2,3],[4,5,6],[7,8,9]])\n",
    "a = 10\n",
    "print a*mymatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 矩阵所有元素求和：\n",
    "$$sum(A)=\\sum_{i=1}^{m}\\sum_{j=1}^{n}A_{i,j} \\qquad  1<i<m,1<j<n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "mymatrix = mat([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print sum(mymatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 矩阵各元素的积： 矩阵的点乘同维对应元素的相乘。 \n",
    "当矩阵的维度不相同时，会根据一定的广播规则将维数扩充到一致的形式，\n",
    "\n",
    "$$ (A.*B)_{i,j} = A_{i,j} * B_{i,j} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.5   3.    4.5]\n",
      " [  6.    7.5   9. ]\n",
      " [ 10.5  12.   13.5]]\n"
     ]
    }
   ],
   "source": [
    "mymatrix = mat([[1,2,3],[4,5,6],[7,8,9]])\n",
    "mymatrix2 = 1.5*ones((3,3))\n",
    "print multiply(mymatrix,mymatrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 矩阵各元素的 n 次幂： n=2\n",
    "\n",
    "$$ A_{i,j}^2 = A_{i,j} * A_{i,j} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  4  9]\n",
      " [16 25 36]\n",
      " [49 64 81]]\n"
     ]
    }
   ],
   "source": [
    "mymatrix = mat( [[1,2,3],[4,5,6],[7,8,9]])\n",
    "print power(mymatrix,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵的乘法：矩阵乘矩阵\n",
    "\n",
    "$$[A,B]_{i,j}= A_{i,1}B_{1,i}+A_{i,2}B_{1,2}+...+A_{i,n}B_{n,j}=\\sum_{r=1}^{n}A_{i,r}B_{r,j} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14]\n",
      " [32]\n",
      " [50]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "\n",
    "mymatrix = mat( [[1,2,3],[4,5,6],[7,8,9]])\n",
    "mymatrix2 = mat( [[1],[2],[3]])\n",
    "print mymatrix * mymatrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵的转置\n",
    "$$(A^T)_{i,j} = A_{j,i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]]\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "\n",
    "mymatrix = mat( [[1,2,3],[4,5,6],[7,8,9]])\n",
    "print mymatrix.T\n",
    "mymatrix.transpose()\n",
    "print mymatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 矩阵的其他操作：行列数、切片、复制、比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵的行数和列数: 3 3\n",
      "按行切片: [[1 2 3]]\n",
      "按列切片: [[1 4 7]]\n",
      "复制矩阵：\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "矩阵元素的比较:\n",
      "[[False  True  True]\n",
      " [False False  True]\n",
      " [False False False]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "\n",
    "mymatrix = mat( [[1,2,3],[4,5,6],[7,8,9]])\n",
    "[m,n]=shape(mymatix)#矩阵的行列数\n",
    "print \"矩阵的行数和列数:\",m,n\n",
    "\n",
    "myscl1=mymatix[0]#按行切片\n",
    "print \"按行切片:\",myscl1\n",
    "\n",
    "myscl2=mymatix.T[0] #按列切片\n",
    "print \"按列切片:\",myscl2\n",
    "\n",
    "mycpmat = mymatix.copy() #矩阵的复制\n",
    "print \"复制矩阵：\\n\",mycpmat\n",
    "\n",
    "#比较\n",
    "print \"矩阵元素的比较:\\n\",mymatix < mymatix.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linalg 线性代数库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "在矩阵基本运算的基础之上，Numpy的 linalg库可以满足大多数的线性代数运算，\n",
    "本节所列的矩阵公式列表和代码如下：\n",
    "\n",
    " 矩阵的行列式\n",
    "\n",
    " 矩阵的逆\n",
    "\n",
    " 矩阵的对称\n",
    "\n",
    " 矩阵的秩\n",
    "\n",
    " 可逆矩阵求解线性方程组\n",
    "\n",
    "读者可根据自己需求有选择的学习。因使用矢量编程的方法，矩阵的基本运算得\n",
    "到了较大的简化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵的行列式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det(A): -812.0\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "# n 阶方阵的行列式运算\n",
    "A = mat( [[1,2,4,5,7,],[9,12,11,8,2,],[6,4,3,2,1,],[9,1,3,4,5],[0,2,3,4,1]])\n",
    "print \"det(A):\",linalg.det(A); # 方阵的行列式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵的逆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv(A): [[ -7.14285714e-02  -1.23152709e-02   5.29556650e-02   9.60591133e-02\n",
      "   -8.62068966e-03]\n",
      " [  2.14285714e-01  -3.76847291e-01   1.22044335e+00  -4.60591133e-01\n",
      "    3.36206897e-01]\n",
      " [ -2.14285714e-01   8.25123153e-01  -2.04802956e+00   5.64039409e-01\n",
      "   -9.22413793e-01]\n",
      " [  1.66901077e-16  -4.13793103e-01   8.79310345e-01  -1.72413793e-01\n",
      "    8.10344828e-01]\n",
      " [  2.14285714e-01  -6.65024631e-02   1.85960591e-01  -8.12807882e-02\n",
      "   -1.46551724e-01]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "# n 阶方阵的行列式运算\n",
    "A = mat( [[1,2,4,5,7,],[9,12,11,8,2,],[6,4,3,2,1,],[9,1,3,4,5],[0,2,3,4,1]])\n",
    "invA=linalg.inv(A) #矩阵的逆\n",
    "print \"inv(A):\",invA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵的对称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 95 131  43  78  43]\n",
      " [131 414 153 168  91]\n",
      " [ 43 153  66  80  26]\n",
      " [ 78 168  80 132  32]\n",
      " [ 43  91  26  32  30]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "# n 阶方阵的行列式运算\n",
    "A = mat( [[1,2,4,5,7,],[9,12,11,8,2,],[6,4,3,2,1,],[9,1,3,4,5],[0,2,3,4,1]])\n",
    "AT=A.T #矩阵的对称\n",
    "print A*AT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵的秩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "# n 阶方阵的行列式运算\n",
    "A = mat( [[1,2,4,5,7,],[9,12,11,8,2,],[6,4,3,2,1,],[9,1,3,4,5],[0,2,3,4,1]])\n",
    "print linalg.matrix_rank(A) #矩阵的秩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 可逆矩阵求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0270936   1.77093596 -3.18472906  1.68965517  0.25369458]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "A = mat([[1,2,4,5,7,],[9,12,11,8,2,],[6,4,3,2,1,],[9,1,3,4,5],[0,2,3,4,1]])\n",
    "b = [1,0,1,0,1]\n",
    "S = linalg.solve(A,b)\n",
    "print S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 机器学习的数学基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一谈到数学，大多数人的感\n",
    "觉就一个字：晕。其实，数学让人觉得难的地方不外乎两点：一是语言符号非常简练，二是理论描述比较抽象。\n",
    "\n",
    "现代数学有三个重要的基石：概率论、数值分析、线性代数。\n",
    ">* 概率论说明了事物\n",
    "可能会是什么样；\n",
    ">* 数值分析揭示了它们为什么这样，以及如何变成这样；\n",
    ">* 线性代数则\n",
    "告诉我们事物从来不只有一个样子，使我们能从多个角度来观察事物。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相似度的度量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**范数(来自百度百科): **向量的范数可以简单形象的理解为向量的长度，或者向量到\n",
    "坐标系原点的距离，或者相应空间内的两个点之间的距离。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "向量的范数定义：向量的范数是一个函数||x||,满足非负性||x|| >= 0，齐次性\n",
    "||cx|| = |c| ||x|| ，三角不等式||x+y|| <= ||x|| + ||y||\n",
    "\n",
    ">* L1 范数: ||x||为 x 向量各个元素绝对值之和。\n",
    "\n",
    ">* L2 范数: ||x||为 x 向量各个元素平方和的开方， L2 范数又称 Euclidean 范数或\n",
    "者 Frobenius 范数\n",
    "\n",
    ">* Lp 范数: ||x||为 x 向量各个元素绝对值 p 次方和的 1/p 次方\n",
    "\n",
    ">* L∞范数: ||x||为 x 向量各个元素绝对值最大那个元素，如下：\n",
    "$$\\lim_{k\\rightarrow \\infty }\\left ( \\sum_{i=1}^{n} \\left | p_{i} - q_{i} \\right |^{k} \\right )^{1/k}$$\n",
    "\n",
    "向量范数的运算:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modA: 10.0498756211\n",
      "norm(A): 10.0498756211\n"
     ]
    }
   ],
   "source": [
    "A= [8,1,6]\n",
    "#手工计算\n",
    "modA=sqrt(sum(power(A,2)))\n",
    "print \"modA:\",modA\n",
    "#库函数\n",
    "normA = linalg.norm(A)\n",
    "print \"norm(A):\",normA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "本节所列的距离公式列表和代码如下：\n",
    ">* 闵可夫斯基距离(Minkowski Distance)\n",
    ">* 欧氏距离(Euclidean Distance)\n",
    ">* 曼哈顿距离(Manhattan Distance)\n",
    ">* 切比雪夫距离(Chebyshev Distance)\n",
    ">* 夹角余弦(Cosine)\n",
    ">* 汉明距离(Hamming distance)\n",
    ">* 杰卡德相似系数(Jaccard similarity coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各类距离的意义与python实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 闵可夫斯基距离(Minkowski Distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "严格意义上， 闵氏距离不是一种距离，而是一组距离的定义。\n",
    "\n",
    "两个 n 维变量 $A(x_{11},x_{12},…,x_{1n})$与 $B(x_{21},x_{22},…,x_{2n})$间的闵可夫斯基距离定义为：\n",
    "\n",
    "$$d_{12} = \\sqrt[p]{\\sum_{k=1}^{n}\\left ( x_{1k} - x_{2k}  \\right )^p }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中p是一个变参数.\n",
    "   - [ ] 当p=1时，就是曼哈顿距离\n",
    "   - [ ] 当p=2时，就是欧式距离\n",
    "   - [ ] 当$p\\rightarrow \\infty $时，就是切比雪夫距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 欧氏距离(Euclidean Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.19615242]]\n"
     ]
    }
   ],
   "source": [
    "# python实现欧式距离\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "v1 = mat([1,2,3])\n",
    "v2 = mat([4,5,6])\n",
    "print sqrt((v1-v2)*(v1-v2).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 曼哈顿距离(Manhattan Distance)\n",
    "两个 n 维变量 $A(x_{11},x_{12},…,x_{1n})$与 $B(x_{21},x_{22},…,x_{2n})$间的曼哈顿距离定义为：\n",
    "$$d_{12} = \\sum_{k=1}^{n}\\left | x_{1k}- x_{2k} \\right |$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "\n",
    "v1 = mat([1,2,3])\n",
    "v2 = mat([4,5,6])\n",
    "print sum(abs(v1-v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 切比雪夫距离(Chebyshev Distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个 n 维变量 $A(x_{11},x_{12},…,x_{1n})$与 $B(x_{21},x_{22},…,x_{2n})$ 间的切比雪夫距离定义为：\n",
    "$$d_{12} = \\max_{i}\\left ( \\left | x_{1i} - x_{2i} \\right | \\right )$$\n",
    "等价形式\n",
    "$$d_{12} = \\lim_{k\\rightarrow \\infty } \\left ( \\sum_{i=1}^{n}\\left |  x_{1i} - x_{2i} \\right |^{k} \\right )^{1/k}$$\n",
    "\n",
    "**等价性证明？**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "\n",
    "v1 = mat([1,2,3])\n",
    "v2 = mat([4,7,9])\n",
    "\n",
    "print abs((v1 - v2)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 夹角余弦(Cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "几何中夹角余弦可用来衡量两个向量方向的差异，机器学习中借用这一概念来衡量样本向量之间的差异\n",
    "\n",
    "![](fig1_12.PNG)\n",
    "\n",
    "2维\n",
    "$$cos (\\theta ) =  \\frac{x_{1}x_{2} + y_{1}y_{2}}{\\sqrt{(x_{1}^2+y_{1}^2)}\\sqrt{(x_{2}^2+y_{2}^2)}}$$\n",
    "\n",
    "\n",
    "n维\n",
    "$$cos (\\theta ) =  \\frac{\\mathbf{A}\\mathbf{B}}{\\left | \\mathbf{A} \\right | \\left | \\mathbf{B} \\right |}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.92966968]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "\n",
    "v1 = mat([1,2,3])\n",
    "v2 = mat([4,7,5])\n",
    "cosv = dot(v1,v2.T)/(linalg.norm(v1)*linalg.norm(v2))\n",
    "print cosv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 汉明距离(Hamming distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个等长字符串 s1 与 s2 之间的汉明距离定义为将其中一个变为另外一个所需要\n",
    "作的最小替换次数。例如字符串\"1111\"与\"1001\"之间的汉明距离为 2。\n",
    "\n",
    "应用：信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "matV = mat([[1,1,0,1,0,1,0,0,1],[0,1,1,0,0,0,1,1,1]])\n",
    "smstr = nonzero(matV[0]-matV[1]);\n",
    "# print (matV[0]-matV[1]);\n",
    "# print smstr\n",
    "print shape(smstr)[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 杰卡德相似系数(Jaccard similarity coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)杰卡德相似系数\n",
    "\n",
    "两个集合 A 和 B 的交集元素在 A，B 的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号 J(A,B)表示。\n",
    "$$J(A,B)=\\frac{A \\cap  B}{ A \\cup  B }$$\n",
    "\n",
    "杰卡德相似系数是衡量两个集合的相似度一种指标。\n",
    "\n",
    "(2)杰卡德距离\n",
    "\n",
    "与杰卡德相似系数相反的概念是杰卡德距离(Jaccard distance)。杰卡德距离可用如\n",
    "下公式表示：\n",
    "$$J_{\\delta  }(A, B) = 1 - J(A, B)=\\frac{  \\left | A \\cup  B \\right |  - \\left |  A \\cap  B \\right |}{\\left |  A \\cup  B \\right | }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist.jaccard: [ 0.75]\n",
      "[ 2.44948974]\n",
      "[ 2.44948974]\n",
      "[ 6.]\n",
      "[ nan]\n",
      "[ 6.]\n",
      "[ 0.6]\n",
      "[ 1.35]\n",
      "[ 0.66666667]\n",
      "[ 0.75]\n",
      "[ 1.]\n",
      "[ 6.]\n",
      "[ 0.6]\n",
      "[ 1.63636364]\n",
      "[ 0.66666667]\n",
      "[ 0.6]\n",
      "[ 0.86666667]\n",
      "[ 0.8]\n",
      "[ 0.77777778]\n",
      "[ 0.8]\n",
      "[ 0.85714286]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "import scipy.spatial.distance as dist # 导入 scipy 距离公式\n",
    "matV = mat([[1,1,0,1,0,1,0,0,1],[0,1,1,0,0,0,1,1,1]])\n",
    "print \"dist.jaccard:\", dist.pdist(matV,'jaccard')\n",
    "\n",
    "# dist.pdist可实现各种距离\n",
    "print dist.pdist(matV, 'euclidean')\n",
    "print dist.pdist(matV, 'minkowski', 2)\n",
    "print dist.pdist(matV, 'cityblock')\n",
    "print dist.pdist(matV, 'seuclidean', V=None)\n",
    "print dist.pdist(matV, 'sqeuclidean')\n",
    "print dist.pdist(matV, 'cosine')\n",
    "print dist.pdist(matV, 'correlation')\n",
    "print dist.pdist(matV, 'hamming')\n",
    "print dist.pdist(matV, 'jaccard')\n",
    "print dist.pdist(matV, 'chebyshev')\n",
    "print dist.pdist(matV, 'canberra')\n",
    "print dist.pdist(matV, 'braycurtis')\n",
    "#print dist.pdist(matV, 'mahalanobis', VI=None)\n",
    "print dist.pdist(matV, 'yule')\n",
    "print dist.pdist(matV, 'matching')\n",
    "print dist.pdist(matV, 'dice')\n",
    "print dist.pdist(matV, 'kulsinski')\n",
    "print dist.pdist(matV, 'rogerstanimoto')\n",
    "print dist.pdist(matV, 'russellrao')\n",
    "print dist.pdist(matV, 'sokalmichener')\n",
    "print dist.pdist(matV, 'sokalsneath')\n",
    "#print dist.pdist(matV, 'wminkowski')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们有能力为矩阵中对象间的相似程度(接近与远离)提供各种度量方法，以及编码实现。通过计算对象间的距离，我们就可以轻松地得到表 2.8 中的四个对象所属的类别：以克、天为单位的苹果是水果类别的一个实例; 以吨、年为单位鲨鱼是大型动物的一个实例。这种区别是明显的。\n",
    "\n",
    "但是，如果我们考察颜色这个特征，情况可能会有所不同，苹果和梨都有黄色这个特征，像这种情况我们如何区分呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 理解随机性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们改变一下视角，从整体上观察矩阵(集合)中的对象分布与矩阵整体的关系。这需要引入一个新的概念：概率论。\n",
    "\n",
    "想要真正理解概率需要弄清楚两个问题：\n",
    ">* 确定性和随机性\n",
    ">* 统计规律\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1963 年，美国气象学家洛仑兹建立了一个描述大气对流状况的数学模型，叫洛仑兹动力学方程。这是个简单确定性方程。因为它只有三个变量用来分别代表大气中的风速、温度和气压；说它是确定性的，因为不含任何随机项，初始值也可以给定。但就是由这个方程所描述的只有三个变量的简单确定性系统里，却让我们出乎意料地见到了随机性的一个典型特征：**混沌**，见识了混沌非比寻常的特性。\n",
    "\n",
    "洛仑兹动力学方程描绘出的运动轨迹，它具有一种奇特的形状，像一只展开了双翼的蝴蝶，所以又称为**蝴蝶效应**。\n",
    "![](fig1_13.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果从统计学的角度来看，蝴蝶效应说明了两方面的意义：一方面，样本总体（特征向量）的取值范围一般是确定的，所有样本对象（包括已经存在的和未出现的）的取值都位于此空间范围内。另一方面，无论搜集再多的样本对象，也不能使这种随机性降低或者消失。**因此，随机性是事物的一种根本的、内在的、无法根除的性质，也是一切事物（概率）的本质属性**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回顾概率论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "为了更好的理解，我们修改一下上面的例子，假设我们的集合中只有苹果和梨两大类的对象，苹果有 10 个，梨也有 10 个，这次我们仅考察颜色特征。苹果有两种颜色：红色或黄色，其中红色占了 8 个；梨也有两种颜色：黄色或绿色，其中黄色占9个，假如从这堆水果中挑出一个黄色水果，问这个水果属于梨的可能性。\n",
    "\n",
    "----\n",
    "    概率论基础概念：\n",
    "- **样本(样本点)**：原指随机实验一个结果，可以理解为矩阵中的一个对象：苹果或梨；\n",
    "- **样本空间**：原指随机实验所有结果的集合，可以理解为矩阵的所有对象，引申为对象特征的取值范围：10 个苹果，10 个梨；\n",
    "- **随机事件**：是指样本空间的一个子集，可以理解为某个分类，它实际指向一种概率分布：苹果为红色；梨为黄色；\n",
    "- **随机变量**：可以理解为指向某个事件的一个变量：X{x=黄色}\n",
    "- **随机变量的概率分布**：给定随机变量的取值范围，导致某种随机事件出现的可能性，从机器学习的角度来看，就是符合随机变量取值范围的某个对象属于某个类别或服从某种趋势的可能性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概率论妙处在于，由于随机性的存在，有时候无法直接讨论随机变量如何从样本空间映射到事件空间，因为随机变量的取值范围允许它可以映射到事件空间中的任一事件。此时，只有通过研究随机变量映射为每个事件的可能性，也就是说某个对象属于每个类别的可能性，才能做出合理的判断。理解了这一层也就理解了概率论的数学本质。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个问题的求解过程就是著名的贝叶斯公式：\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用数学的语言来表达，就是已知 P(苹果)=10/(10+10)，P(梨)=10/(10+10)，P(黄色|苹果)=20%，P(黄色|梨)=90%，求 P(梨|黄色)\n",
    "\n",
    "可得：P(梨|黄色)=P(黄色,梨)/P(黄色)\n",
    "\n",
    "=P(黄色|梨)P(梨)/P(黄色)\n",
    "\n",
    "=81.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯公式贯穿了机器学习中随机问题分析的全过程。从文本分类到概率图模型，其基本原理都是贝叶斯公式，是**机器学习领域最重要的基础概念**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多元统计基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "矩阵是具有相同特征和维度的对象集合，其中每个对象，也称为行向量，都具有一个以上特征。如果，每个特征都用一个随机变量来表示，那么从概率论的角度，一个对象就可以表示为 n 个随机变量的整体，其中 X=(X1,X2, …，Xn)为 n 维随机变量或随机向量。每个对象就是随机向量的一组取值，矩阵中的所有对象构成了随机向量的**联合和边缘概率分布**。\n",
    "![](table1_8.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表中间白色部分是水果和颜色两个特征的**联合概率**分布，灰色部分是两个特征各自取值的**边缘概率**分布。形式上，以二维随机变量为例，X，Y 的联合概率分布为：\n",
    "$$P\\left \\{ X=x_{i},Y=y_{j}\\right \\}  = P_{i,j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征间的相关性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机变量，一般是一个向量，可以包含不同取值范围的多个变量，有必要研究一下这些变量的分布情况，也就是随机变量的数字特征，从中发掘出一定的规律性：\n",
    ">* 期望：衡量样本某个特征列取值范围的平均值\n",
    ">* 方差：衡量样本某个特征列取值范围的离散程度\n",
    ">* 协方差矩阵和相关系数：衡量样本特征列之间线性相关性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 相关系数 ( Correlation coefficient )与相关距离(Correlation distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相关系数的定义：\n",
    "$$\\rho _{XY} = \\frac{Cov(X,Y)}{\\sqrt{D(X)}\\sqrt{D(Y)}} = \\frac{E((X-EX)(Y-EY))}{\\sqrt{D(X)}\\sqrt{D(Y)}}$$\n",
    "相关系数是衡量两个特征列之间相关程度的一种方法，相关系数的取值范围是[-1，1]。相关系数的绝对值越大，则表明特征列 X 与 Y 相关度越高。当 X 与 Y 线性相关时，相关系数取值为 1（正线性相关）或-1（负线性相关）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相关距离的定义：\n",
    "$$D_{X,Y} = 1 - \\rho_{XY}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98160142576\n",
      "[[ 1.          0.98160143]\n",
      " [ 0.98160143  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Python 实现相关系数：数据来源于表 2.6 2-18 岁正常男生体重身高对照表\n",
    "\n",
    "featuremat = mat([[88.5,96.8,104.1,111.3,117.7,124.0,130.0,135.4,140.2,145.3,151.9,159.5,165.9,169.8,171.6,172.3,172.7],[12.54,14.65,16.64,18.98,21.26,24.06,27.33,30.46,33.74,37.69,42.49,48.08,53.37,57.08,59.35,60.68,61.40]])\n",
    "# 计算均值\n",
    "mv1 = mean(featuremat[0]) # 第一列的均值\n",
    "mv2 = mean(featuremat[1]) # 第二列的均值\n",
    "# 计算两列标准差\n",
    "dv1 = std(featuremat[0])\n",
    "dv2 = std(featuremat[1])\n",
    "corref = mean(multiply(featuremat[0]-mv1,featuremat[1]-mv2))/(dv1*dv2)\n",
    "print corref\n",
    "# 使用 numpy 相关系数得到相关系数矩阵\n",
    "print corrcoef(featuremat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相关系数矩阵的含义是，如果把第一个特征列作为参照数据(自己与自己的相关程度为 1)，那么第二个与第一个的相关程度是 98%。\n",
    "\n",
    "\n",
    "有了数字特征，下面我们可以发展欧氏距离公式为马氏距离公式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 马氏距离(Mahalanobis Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "263px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "795px",
    "left": "0px",
    "right": "1708px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
